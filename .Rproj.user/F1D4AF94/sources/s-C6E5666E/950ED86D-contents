---
title: "Analítica de Datos Aplicada"
subtitle: "Classification and Regression Trees"
author:
  - Jorge I. Vélez^[Profesor Asistente, Departamento de Ingeniería Industrial, Universidad del Norte, Barranquilla, Colombia. jvelezv@uninorte.edu.co]
fontsize: 13pt
header-includes:
  - \usepackage{amssymb}
  - \usepackage{latexsym}
  - \usepackage{amsmath} 
  - \usepackage{amsthm} 
  - \usepackage{bm} 
date: "Septiembre 28, 2021"
lang: "es-ES"
output: 
  html_document: 
    theme: readable #default, cerulean, journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, and yeti.
    highlight: textmate # default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, and textmate
    number_sections: false
    fig_caption: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<hr>

## Introducción

Los Árboles de Clasificación y Regresión (CART en inglés) fueron propuestos por [Breiman, Friedman, Olshen y Stone](https://www.amazon.com/-/es/Leo-Breiman/dp/0412048418/ref=sr_1_1?__mk_es_US=%C3%85M%C3%85%C5%BD%C3%95%C3%91&dchild=1&keywords=Classification+and+Regression+Trees&qid=1632755928&s=books&sr=1-1) en 1984.

<br>

```{r cartbook, echo=FALSE, out.width="35%", fig.cap="El comienzo de CART. Imagen tomada de [aquí](https://towardsdatascience.com/the-complete-guide-to-decision-trees-28a4e3c7be14).", fig.align='center', message=FALSE}
require(knitr)
knitr::include_graphics("https://images-na.ssl-images-amazon.com/images/I/41vRlYmYYxL._SX334_BO1,204,203,200_.jpg")
```

<br>

La gran ventaja de los modelos CART es que son fáciles de entender y son métodos no paramétricos que permiten la inclusión de relaciones no lineales en los datos. Dentro de las *dificultades* que existen al utilizar modelos CART se encuentran (1) *overfitting*, (2) *high variance* y (3) *low bias* . Para más detalles, se recomienda ver [este](https://www.digitalvidya.com/blog/classification-and-regression-trees/#:~:text=A%20Classification%20and%20Regression%20Tree,prediction%20for%20the%20target%20variable.) enlace y la Sesión \#[19](https://drive.google.com/drive/folders/11SL6uk9MTfAWMQITI-HvTPmHsnVJlyow?usp=sharing) del curso.

```{r bootimage, echo=FALSE, out.width="85%", fig.cap="Componentes básicos de CART. Imagen tomada de [aquí](https://www.amazon.com/-/es/Leo-Breiman/dp/0412048418/ref=sr_1_1?__mk_es_US=%C3%85M%C3%85%C5%BD%C3%95%C3%91&dchild=1&keywords=Classification+and+Regression+Trees&qid=1632755928&s=books&sr=1-1).", fig.align='center', message=FALSE}
require(knitr)
knitr::include_graphics("https://miro.medium.com/max/1540/0*IS9xKHt83nuERC9P")
```

<br>

En esta práctica de `R` trabajaremos la sintaxis para ajustar modelos CART a través de diferentes ejemplos.

Inicialmente, debemos chequear la disponibilidad de los paquetes que usaremos:

```{r, message=FALSE}
## paquetes para este laboratorio
if(!require(rpart)) install.packages('rpart')
require(rpart)

if(!require(rattle)) install.packages('rattle')
require(rattle)

if(!require(rpart.plot)) install.packages('rpart.plot')
require(rpart.plot)

if(!require(party)) install.packages('party')
require(party)

if(!require(partykit)) install.packages('partykit')
require(partykit)

if(!require(caret)) install.packages('caret')
require(caret)

if(!require(vip)) install.packages('vip')
require(vip)
```

<hr>

## Ejemplo

### Funciones

Inicialmente, cargamos las funciones que hemos utilizado con anterioridad para evaluar el desempeño del Modelo de [Regresión Logística](https://drive.google.com/drive/folders/1-clwRTv7XO1A_GIcFdVvaaVS1UNow-HD?usp=sharing).

```{r, message=FALSE}
## load functions
source('https://www.dropbox.com/s/xclvdugfbrf5ryn/logistic-functions.R?dl=1')
```

### Datos

Consideraremos los siguientes datos:

```{r}
## lectura de datos
d <- read.table("https://www.dropbox.com/s/bxea58hj951vi7k/datos-p1-caso2.txt?dl=1", 
                header = TRUE)
## primeras 3 filas
head(d, 3)
```

Las variables relevantes son `y` que corresponde al diagnóstico de la persona y $x_j$ que establece si el $j$-ésimo síntoma está presente o no $(j=1,2,\ldots,20).$

En el caso de la variable `y` tenemos

```{r}
## variable y
with(d, table(y))
```

Para las variables independientes se tiene que

```{r, fig.align='center'}
p <- apply(d[,-c(1, 2)], 2, tapply, d$y, function(x) 100*mean(x == 1))
p <- t(p)
freq <- data.frame(symptom = rep(1:NROW(p), 2), p = c(p[,1], p[,2]), adhd = rep(c('no', 'yes'), each = 20))
require(ggplot2)
ggplot(freq, aes(x = symptom, y = p, fill = adhd, col - adhd)) + geom_line(aes(color = adhd)) + 
  ylab("Percentage (x100)") +
  theme_minimal()
```

A partir de esta gráfica podemos concluir que, en definitiva, la presencia/ausencia de algunos síntomas podría ser determinante para la predicción del diagnóstico.


### Modelo CART

En la práctica, la construcción de un modelo predictivo se realiza utilizando datos de _training_ y datos de _testing_. Estos dos conjuntos de datos provienen de los datos originales.  Generalmnete, el conjunto de _training_ corresponde al 70% u 80% de las observaciones originales, y el conjunto de _testing_ al restante 30% o 20%.

```{r}
## selección de los datos y operaciones
d <- d[,-1] 
d[,-1] <- apply(d[,-1], 2, as.factor)
d$y <- factor(d$y, levels = c('yes', 'no'))

## crear particion
set.seed(123)
intrain <- createDataPartition(y = d$y, p= 0.7, list = FALSE)
training <- d[intrain,]
testing <- d[-intrain,]
```

Ahora ajustamos el modelo CART utilizando la función `train` del paquete `caret`. Observe que usamos $10-$fold _cross validation_. Como en el algoritmo implementado en `rpart` debe optimizarse el parámetro `cp`, usamos el argumento `tuneLength` para evalúe 30 valores diferentes. Para más información, ver https://topepo.github.io/caret/available-models.html

```{r, message=FALSE}
## ajuste del modelo CART
set.seed(123)
cartmodel <- train(
  y ~., data = training, method = "rpart",
  trControl = trainControl("cv", number = 10),
  tuneLength = 30
)
```


Gráficamente los resultados pueden representarse haciendo

```{r, fig.align='center', fig.width=5.5, fig.height=5.5}
# cp (complexity parameter)
plot(cartmodel)
```

Para obtener la mejor combinacion de parámetros hacemos:

```{r}
## mejor modelo
cartmodel$bestTune
```

Si queremos graficar el árbol para _el modelo final_ hacemos

```{r, fig.align='center'}
# grafico del modelo final 
par(xpd = NA)  
plot(cartmodel$finalModel)
text(cartmodel$finalModel, digits = 3)
```

Inclusive, podemos mejorar el gráfico con la función `fancyRpartPlot` del paquete `rattle`:

```{r, fig.align='center'}
## un árbol estéticamente mejor
par(mfrow = c(1,1), mar = c(2, 2, 2, 2))
fancyRpartPlot(cartmodel$finalModel, sub = "")
```

### Evaluación del modelo

Otra posibilidad para dibujar el árbol es la función `prp` del paquete `rpart.plot`. Para más detalles, ver [este](https://fhernanb.github.io/libro_mod_pred/arb-de-regre.html#ejemplo-con-el-paquete-rpart) ejemplo.

Ahora, con el modelo CART almacenado en el objeto `cartmodel` podemos proceder a hacer predicción para los datos de _training_:

```{r}
## matriz de confusión para training
classpred <- predict(cartmodel, newdata = training)
(mtraining <- table(classpred, classreal = training$y))
```
Las medidas de desempeño para la matriz de confusión de _training_ pueden obtenerse haciendo

```{r}
## performance en training
measures(mtraining)
```

Para los datos de _testing_ procedemos de manera similar:

```{r}
## matriz de confusión para testing
classpred <- predict(cartmodel, newdata = testing)
(mtesting <- table(classpred, classreal = testing$y))
```

Las medidas de desempeño pueden obtenerse haciendo

```{r}
## performance en testing
measures(mtesting)
```

### Variable importance

A partir del modelo CART ajustado podemos extraer las 10 variables más importantes para predecir el diagnóstico de la enfermedad:

```{r}
## variable importance
par(mar = c(4, 8, 2, 1))
res <- vip(cartmodel, num_features = 10)$data 
res <- as.data.frame(res)
res$Variable <- substr(res$Variable, 1, nchar(res$Variable) - 1)
res
```

El gráfico podemos obtenerlo haciendo

```{r, fig.align='center', fig.width=5.5, fig.height=5.5}
## viplot
par(mfrow = c(1,1))
vi <- res$Importance
names(vi) <- res$Variable
barplot(rev(vi), horiz = TRUE, col = cols[1], border = cols[1], las = 1, space = .2)
mtext('Variable Importance Score', side = 1, line = 2.5)
```

Una forma más sencilla de obtener el mismo gráfico con la función [`vip`](https://koalaverse.github.io/vip/articles/vip.html):

```{r, fig.align='center', fig.width=5.5, fig.height=5.5}
## viplot con el paquete vip
vip(cartmodel)
```

### Curvas ROC

Finalmente, las curva ROC para _training_ y _testing_ podemos obtenerla de la siguiente manera:

```{r, fig.align='center', fig.width=5, fig.height=5}
## ROC curves
roc_training <- rft(mtraining, las = 1, line.col = cols[1])
roc_testing <- rft(mtesting, las = 1, line.col = cols[2], add = TRUE)
legend('bottomright', c('training', 'testing'), col = cols[1:2], lty = 1, bty = 'n')
```
Los AUCs pueden obtenerse con

```{r}
## AUC para training
roc_training$auc
```

```{r}
## AUC para testing
roc_testing$auc
```

En general, el modelo CART para predecir el diagnóstico de la enfermedad es _bueno_.


### Predicción

Si una persona presenta los síntomas `x1`, `x5` y `x7`, cuál sería el diagnóstico más probable?

La predicción del diagnóstico para esta persona podemos hacerla con la función `predict()` de la siguiente manera:

```{r}
predict(cartmodel, newdata = 
         data.frame(x1 = "1", x2 = "0", x3 = "0", 
                    x4 = "0", x5 = "1", x6 = "0", 
                    x7 = "1", x8 = "0", x9 = "0", 
                    x10 = "0", x11 = "0", x12 = "0", 
                    x13 = "0", x14 = "0", x15 = "0", 
                    x16 = "0", x17 = "0", x18 = "0", 
                    x19 = "0", x20 = "0"))
```
Observe que los valores que toman las variables están como `character`, no como `numeric` o `integer.`

Si quisiéramos automatizar el proceso, podemos constuir una función que tomara el objeto `cartmodel` y construyera el `data.frame()` necesario para la predicción:

```{r}
## función para predecir el diagóstico dados los síntomas
predStatus <- function(symptoms, black_box){
	xnew <- rep(0, 20) 
	xnew[symptoms] <- 1
	dnew <- data.frame(t(as.character(xnew)))
	colnames(dnew) <- paste0('x', 1:20)
	predict(black_box, newdata = dnew)	
}
```

En el caso en que `x1=1`, `x5=1` y `x7=1` se tendría que

```{r}
## predicción para una persona con síntomas 1, 5 y 7
symptoms <- c(1, 5, 7)
predStatus(symptoms, cartmodel)
```

Por otro lado, el diagnóstico de una persona con los síntomas 2, 4, 6 y 8 será

```{r}
## predicción para una persona con síntomas 1, 5 y 7
symptoms <- c(2, 4, 6, 8)
predStatus(symptoms, cartmodel)
```

## Más ejemplos

En caso de ser necesario, en los siguientes enlaces se encuentran más ejemplos de modelos CART:

* http://www.sthda.com/english/articles/35-statistical-machine-learning-essentials/141-cart-model-decision-tree-essentials/
* https://rpubs.com/minma/cart_with_rpart



## Homework

1. Use los datos anteriores.
2. Construya el conjunto de _training_ y _testing_ con las proporciones 80/20;
3. Ajuste los modelos CART que se muestra a continuación y determine cuál es el mejor de todos. Use el AUC para comparar.

```{r cartcaret, echo=FALSE, out.width="85%", fig.cap="Modelos CART implementados en `caret`.", fig.align='center', message=FALSE}
require(knitr)
knitr::include_graphics("https://www.dropbox.com/s/eicjxkfjfm6m5o8/cartcaret.png?dl=1")
```

### Nota
Deben trabajar en Grupo y enviar los resultados a jvelezv@uninorte.edu.co antes de las 6 PM del 4 de Octubre, 2021. 

















